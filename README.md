# Home_assignment1
# 🧠 NN-Assignment1-UCM

## 📌 CS5720 - Neural Networks and Deep Learning  
**University of Central Missouri**  
**Department of Computer Science & Cybersecurity**  
**Instructor:** Dr. I-Hua Tsai  
**Semester:** Summer 2025  

---

## 👤 Student Information  
- **Name:** Sharath Chandra Seriyala  
- **Student ID:** 700776646  
- **Course:** CS5720 – Neural Networks and Deep Learning  

---

## 📚 Assignment Overview  

This assignment demonstrates foundational TensorFlow skills through hands-on tasks in:
1. Tensor creation, reshaping, and broadcasting  
2. Loss function implementation and comparison  
3. Neural network training with TensorBoard  
4. Interpretation and analysis of training trends  

---

## ✅ Tasks Completed

### 🔷 1. Tensor Manipulations & Reshaping
- Created a random tensor of shape `(4, 6)`
- Reshaped it to `(2, 3, 4)` and transposed it to `(3, 2, 4)`
- Performed broadcasting with a tensor of shape `(1, 4)` to match `(3, 2, 4)`
- Explained the logic behind broadcasting in TensorFlow

### 🔷 2. Loss Functions & Hyperparameter Tuning
- Implemented Mean Squared Error (MSE) and Categorical Cross-Entropy (CCE)
- Compared loss values for different prediction sets
- Visualized loss values using bar charts via Matplotlib

### 🔷 3. Neural Network Training + TensorBoard
- Built a simple neural network model using TensorFlow
- Trained on the MNIST dataset
- Logged accuracy, loss, and other metrics to `logs/fit/`
- Used TensorBoard to visualize:
  - Training vs validation accuracy/loss
  - Histograms
  - Learning rate curves

### 🔷 4. Analysis (Q&A)
- Answered questions based on TensorBoard results
- Discussed overfitting trends and performance insights directly in the notebook

---

## 📁 Files Included
- `Home_assignment1.ipynb`: Main Colab notebook with all implementations and analysis
- `README.md`: This documentation file

---

## 🚀 How to Run
1. Open `Home_assignment1.ipynb` in Google Colab
2. Run each cell sequentially to replicate results
3. Launch TensorBoard from the notebook to view training logs

---

